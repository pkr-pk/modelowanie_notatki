# Rozdział 5: Resampling Methods

## 5.1 Walidacja krzyżowa

### 5.1.2 Leave-One-Out Cross-Validation

Walidacja krzyżowa z pominięciem jednej obserwacji (Leave-One-Out Cross-Validation, **LOOCV**) jest ściśle powiązany z podejściem zbioru walidacyjnego z sekcji 5.1.1, ale próbuje zaradzić wadom tej metody.

Podobnie jak podejście ze zbiorem walidacyjnym, LOOCV polega na podziale zbioru obserwacji na dwie części. Jednak zamiast tworzyć dwa podzbiory o porównywalnej wielkości, jako zbiór walidacyjny używana jest pojedyncza obserwacja $(x_1, y_1)$, a pozostałe obserwacje $\{(x_2, y_2),...,(x_n, y_n)\}$ tworzą zbiór uczący. Metoda uczenia statystycznego jest dopasowywana na $n − 1$ obserwacjach uczących, a dla wykluczonej obserwacji dokonywana jest predykcja $\hat{y}_1$, używając jej wartości $x_1$. Ponieważ $(x_1, y_1)$ nie była używana w procesie dopasowywania, $MSE_1 = (y_1 − \hat{y}_1)^2$ dostarcza w przybliżeniu nieobciążonej estymacji błędu testowego. Jednakże, chociaż $MSE_1$ jest nieobciążony dla błędu testowego, jest to słaba estymacja, ponieważ ma dużą zmienność, jako że opiera się na pojedynczej obserwacji $(x_1, y_1)$.

Możemy powtórzyć procedurę, wybierając $(x_2, y_2)$ jako dane walidacyjne, ucząc procedurę statystyczną na $n − 1$ obserwacjach $\{(x_1, y_1),(x_3, y_3),...,(x_n, y_n)\}$ i obliczając $MSE_2 = (y_2−\hat{y}_2)^2$. Powtarzanie tego podejścia $n$ razy daje $n$ błędów kwadratowych, $MSE_1,..., MSE_n$. Estymacja LOOCV dla testowego MSE jest średnią z tych $n$ estymacji błędu testowego:

$$CV_{(n)} = \frac{1}{n}\sum_{i=1}^{n} MSE_i. \quad (5.1)$$

Schemat podejścia LOOCV jest zilustrowany na rysunku 5.3.

LOOCV ma kilka istotnych zalet w porównaniu z podejściem zbioru walidacyjnego. Po pierwsze, ma znacznie mniejsze obciążenie. W LOOCV wielokrotnie dopasowujemy metodę uczenia statystycznego, używając zbiorów uczących zawierających $n − 1$ obserwacji, czyli prawie tyle samo, co w całym zbiorze danych. Jest to przeciwieństwo podejścia ze zbiorem walidacyjnym, w którym zbiór uczący stanowi zazwyczaj około połowy oryginalnego zbioru danych. W konsekwencji podejście LOOCV ma tendencję do niezawyżania stopy błędu testowego w takim stopniu, jak robi to podejście ze zbiorem walidacyjnym. Po drugie, w przeciwieństwie do podejścia walidacyjnego, które da różne wyniki przy wielokrotnym stosowaniu z powodu losowości w podziałach na zbiory uczące/walidacyjne, wielokrotne wykonanie LOOCV zawsze da te same wyniki: nie ma losowości w podziałach na zbiory uczące/walidacyjne.

Użyliśmy LOOCV na zbiorze danych `Auto`, aby uzyskać estymację testowego MSE wynikającego z dopasowania modelu regresji liniowej do przewidywania `mpg` przy użyciu funkcji wielomianowych `horsepower`. Wyniki są pokazane na lewym panelu rysunku 5.4.

LOOCV może być kosztowny obliczeniowo do wdrożenia, ponieważ model musi być dopasowywany $n$ razy. Może to być bardzo czasochłonne, jeśli $n$ jest duże, a dopasowanie każdego indywidualnego modelu jest powolne. W przypadku regresji liniowej lub wielomianowej metodą najmniejszych kwadratów, niesamowity skrót sprawia, że koszt LOOCV jest taki sam, jak dopasowanie pojedynczego modelu! Prawdziwa jest następująca formuła:

$$CV_{(n)} = \frac{1}{n}\sum_{i=1}^{n}\left(\frac{y_i - \hat{y}_i}{1 - h_i}\right)^2, \quad (5.2)$$

gdzie $\hat{y}_i$ to i-ta dopasowana wartość z oryginalnego dopasowania metodą najmniejszych kwadratów, a $h_i$ to dźwignia (leverage) zdefiniowana w (3.37) na stronie 99. To jest jak zwykłe MSE, z tym że i-ta reszta jest dzielona przez $1 − h_i$. Dźwignia leży między $1/n$ a 1 i odzwierciedla, w jakim stopniu obserwacja wpływa na własne dopasowanie. Stąd reszty dla punktów o dużej dźwigni są w tej formule zawyżone o dokładnie taką wielkość, aby ta równość była zachowana.

LOOCV jest bardzo ogólną metodą i może być używana z każdym rodzajem modelowania predykcyjnego. Na przykład, moglibyśmy użyć jej z regresją logistyczną lub liniową analizą dyskryminacyjną, lub z dowolną z metod omówionych w późniejszych rozdziałach. Magiczna formuła (5.2) nie jest ogólnie prawdziwa, w którym to przypadku model musi być dopasowywany $n$ razy.

### 5.1.3 $k$-Fold Cross-Validation

Alternatywą dla LOOCV jest ***k*-krotna walidacja krzyżowa (*k*-fold CV)**. Podejście to polega na losowym podziale zbioru obserwacji na $k$ grup, czyli *zbiorów* (folds), o w przybliżeniu równej wielkości. Pierwszy zbiór jest traktowany jako zbiór walidacyjny, a model jest dopasowywany na pozostałych $k − 1$ zbiorach. Następnie obliczany jest błąd średniokwadratowy, $MSE_1$, na obserwacjach w odłożonym zbiorze. Procedura ta jest powtarzana $k$ razy; za każdym razem inna grupa obserwacji jest traktowana jako zbiór walidacyjny. W wyniku tego procesu otrzymujemy $k$ estymacji błędu testowego, $MSE_1, MSE_2,..., MSE_k$. Estymacja $k$-krotnej walidacji krzyżowej jest obliczana przez uśrednienie tych wartości:

$$CV_{(k)} = \frac{1}{k}\sum_{i=1}^{k} MSE_i. \quad (5.3)$$

Rysunek 5.5 ilustruje podejście $k$-krotnej walidacji krzyżowej.

Nietrudno zauważyć, że LOOCV jest szczególnym przypadkiem $k$-krotnej walidacji krzyżowej, w którym $k$ jest równe $n$. W praktyce zazwyczaj wykonuje się $k$-krotną walidację krzyżową, używając $k = 5$ lub $k = 10$. Jaka jest zaleta używania $k = 5$ lub $k = 10$ zamiast $k = n$? Najbardziej oczywistą zaletą jest wydajność obliczeniowa. LOOCV wymaga dopasowania metody uczenia statystycznego $n$ razy. Może to być kosztowne obliczeniowo (z wyjątkiem modeli liniowych dopasowanych metodą najmniejszych kwadratów, w którym to przypadku można użyć wzoru (5.2)). Walidacja krzyżowa jest jednak bardzo ogólnym podejściem, które można zastosować do niemal każdej metody uczenia statystycznego. Niektóre metody uczenia statystycznego mają intensywne obliczeniowo procedury dopasowywania, więc wykonanie LOOCV może stanowić problem obliczeniowy, zwłaszcza jeśli n jest bardzo duże. W przeciwieństwie do tego, wykonanie 10-krotnej walidacji krzyżowej wymaga dopasowania procedury uczenia tylko dziesięć razy, co może być znacznie bardziej wykonalne. Jak zobaczymy w sekcji 5.1.4, mogą istnieć również inne, nieobliczeniowe zalety wykonywania 5-krotnej lub 10-krotnej walidacji krzyżowej, które wiążą się z kompromisem między obciążeniem a wariancją.

Prawy panel rysunku 5.4 przedstawia dziewięć różnych estymacji 10-krotnej walidacji krzyżowej dla zbioru danych `Auto`, z których każda wynika z innego losowego podziału obserwacji na dziesięć zbiorów. Jak widać na rysunku, istnieje pewna zmienność w estymacjach CV w wyniku zmienności w sposobie podziału obserwacji na dziesięć zbiorów. Jednak ta zmienność jest zazwyczaj znacznie niższa niż zmienność w estymacjach błędu testowego, która wynika z podejścia zbioru walidacyjnego (prawy panel rysunku 5.2).

Gdy analizujemy rzeczywiste dane, nie znamy prawdziwego testowego MSE, więc trudno jest określić dokładność estymacji walidacji krzyżowej. Jeśli jednak badamy dane symulowane, możemy obliczyć prawdziwy testowy MSE i w ten sposób ocenić dokładność naszych wyników walidacji krzyżowej. Na rysunku 5.6 przedstawiamy estymacje walidacji krzyżowej i prawdziwe stopy błędu testowego, które wynikają z zastosowania gładzących splajnów do symulowanych zbiorów danych zilustrowanych na rysunkach 2.9–2.11 w Rozdziale 2. Prawdziwy testowy MSE jest wyświetlony na niebiesko. Czarne linie przerywane i pomarańczowe linie ciągłe pokazują odpowiednio estymacje LOOCV i 10-krotnego CV. Na wszystkich trzech wykresach dwie estymacje walidacji krzyżowej są bardzo podobne. W prawym panelu rysunku 5.6 prawdziwy testowy MSE i krzywe walidacji krzyżowej są prawie identyczne. W środkowym panelu rysunku 5.6 oba zestawy krzywych są podobne przy niższych stopniach elastyczności, podczas gdy krzywe CV przeszacowują testowy MSE dla wyższych stopni elastyczności. W lewym panelu rysunku 5.6 krzywe CV mają prawidłowy ogólny kształt, ale niedoszacowują prawdziwego testowego MSE.

Kiedy wykonujemy walidację krzyżową, naszym celem może być określenie, jak dobrze dana procedura uczenia statystycznego będzie działać na niezależnych danych; w tym przypadku interesująca jest faktyczna estymacja testowego MSE. Ale innym razem interesuje nas tylko lokalizacja punktu minimalnego na estymowanej krzywej testowego MSE. Dzieje się tak, ponieważ możemy przeprowadzać walidację krzyżową na wielu metodach uczenia statystycznego lub na jednej metodzie z różnymi poziomami elastyczności, aby zidentyfikować metodę, która daje najniższy błąd testowy. W tym celu ważna jest lokalizacja punktu minimalnego na estymowanej krzywej testowego MSE, ale faktyczna wartość estymowanego testowego MSE nie jest. Na rysunku 5.6 widzimy, że pomimo faktu, iż czasami niedoszacowują one prawdziwego testowego MSE, wszystkie krzywe CV zbliżają się do zidentyfikowania prawidłowego poziomu elastyczności — czyli poziomu elastyczności odpowiadającego najmniejszemu testowemu MSE.

### 5.1.4 Kompromis między obciążeniem a wariancją dla $k$-krotnej walidacji krzyżowej

Wspomnieliśmy w sekcji 5.1.3, że $k$-krotna walidacja krzyżowa ($k$-fold CV) z $k < n$ ma przewagę obliczeniową nad LOOCV. Jednak pomijając kwestie obliczeniowe, mniej oczywistą, ale potencjalnie ważniejszą zaletą $k$-krotnego walidacji krzyżowej jest to, że często daje on dokładniejsze estymacje stopy błędu testowego niż LOOCV. Ma to związek z kompromisem między obciążeniem a wariancją.

Wspomniano w sekcji 5.1.1, że podejście ze zbiorem walidacyjnym może prowadzić do przeszacowania stopy błędu testowego, ponieważ w tym podejściu zbiór uczący używany do dopasowania metody uczenia statystycznego zawiera tylko połowę obserwacji z całego zbioru danych. Idąc tym tropem, nietrudno zauważyć, że LOOCV da w przybliżeniu nieobciążone estymacje błędu testowego, ponieważ każdy zbiór uczący zawiera $n − 1$ obserwacji, co stanowi prawie tyle samo, co liczba obserwacji w pełnym zbiorze danych. Z kolei wykonanie $k$-krotnego walidacji krzyżowej, na przykład dla $k = 5$ lub $k = 10$, doprowadzi do pośredniego poziomu obciążenia, ponieważ każdy zbiór uczący zawiera w przybliżeniu $(k − 1)n/k$ obserwacji — mniej niż w podejściu LOOCV, ale znacznie więcej niż w podejściu ze zbiorem walidacyjnym. Dlatego z perspektywy redukcji obciążenia jest jasne, że LOOCV jest preferowane nad $k$-krotną walidacją krzyżową.

Wiemy jednak, że obciążenie nie jest jedynym źródłem troski w procedurze estymacji; musimy również wziąć pod uwagę wariancję procedury. Okazuje się, że LOOCV ma wyższą wariancję niż $k$-krotna walidacja krzyżowa z $k < n$. Dlaczego tak się dzieje? Kiedy wykonujemy LOOCV, w efekcie uśredniamy wyniki n dopasowanych modeli, z których każdy jest uczony na prawie identycznym zbiorze obserwacji; dlatego te wyniki są ze sobą silnie (dodatnio) skorelowane. W przeciwieństwie do tego, kiedy wykonujemy $k$-krotna walidacja krzyżowa z $k < n$, uśredniamy wyniki $k$ dopasowanych modeli, które są ze sobą nieco mniej skorelowane, ponieważ nakładanie się zbiorów uczących w każdym modelu jest mniejsze. Ponieważ średnia wielu silnie skorelowanych wielkości ma wyższą wariancję niż średnia wielu wielkości, które nie są tak silnie skorelowane, estymacja błędu testowego wynikająca z LOOCV ma tendencję do posiadania wyższej wariancji niż estymacja błędu testowego wynikająca z $k$-krotnego walidacji krzyżowej.

Podsumowując, istnieje kompromis między obciążeniem a wariancją związany z wyborem $k$ w $k$-krotnej walidacji krzyżowej. Zazwyczaj, biorąc pod uwagę te względy, wykonuje się $k$-krotna walidacja krzyżowa, używając $k = 5$ lub $k = 10$, ponieważ empirycznie wykazano, że te wartości dają estymacje stopy błędu testowego, które nie cierpią ani z powodu nadmiernie wysokiego obciążenia, ani z powodu bardzo wysokiej wariancji.